{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0_2.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10000_4.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10001_1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10002_3.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>neg</td>\n",
       "      <td>10003_3.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                             review label  \\\n",
       "0           0  test  Once again Mr. Costner has dragged out a movie...   neg   \n",
       "1           1  test  This is an example of why the majority of acti...   neg   \n",
       "2           2  test  First of all I hate those moronic rappers, who...   neg   \n",
       "3           3  test  Not even the Beatles could write songs everyon...   neg   \n",
       "4           4  test  Brass pictures (movies is not a fitting word f...   neg   \n",
       "\n",
       "          file  \n",
       "0      0_2.txt  \n",
       "1  10000_4.txt  \n",
       "2  10001_1.txt  \n",
       "3  10002_3.txt  \n",
       "4  10003_3.txt  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('imdb_master.csv', encoding = \"ISO-8859-1\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type      0\n",
      "review    0\n",
      "label     0\n",
      "dtype: int64\n",
      "\n",
      "unsup    50000\n",
      "pos      25000\n",
      "neg      25000\n",
      "Name: label, dtype: int64\n",
      "\n",
      "train    75000\n",
      "test     25000\n",
      "Name: type, dtype: int64\n",
      "\n",
      "Average review length: 1319 words\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns='Unnamed: 0') # don't need\n",
    "df = df.drop(columns='file') # don't need\n",
    "print(df.isna().sum(), end = '\\n\\n') # check if any NA values\n",
    "print(df['label'].value_counts(), end = '\\n\\n')\n",
    "print(df['type'].value_counts(), end = '\\n\\n')\n",
    "print('Average review length:', int(df['review'].apply(lambda x: len(x)).mean()), 'words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['label'] != 'unsup'] # not using any ratings that don't have pos/neg labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    once again mr costner has dragged out a movie ...\n",
      "1    this is an example of why the majority of acti...\n",
      "2    first of all i hate those moronic rappers who ...\n",
      "3    not even the beatles could write songs everyon...\n",
      "4    brass pictures movies is not a fitting word fo...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# clean up punctuation so a review is turned into words only \n",
    "\n",
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\*)|(\\$)|(\\&)|(\\#)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = [REPLACE_NO_SPACE.sub(\"\", line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(\" \", line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "df['review'] = preprocess_reviews(df['review'])\n",
    "print(df['review'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    mr costner dragged movie far longer necessary ...\n",
      "1    example majority action films generic boring t...\n",
      "2    first hate moronic rappers couldnt act gun pre...\n",
      "3    even beatles could write songs everyone liked ...\n",
      "4    brass pictures movies fitting word really some...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# get rid of stop words (words like 'if', 'but', 'we', 'he') which won't help predicing sentiment\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split() \n",
    "                      if word not in stop_words])\n",
    "        )\n",
    "    return removed_stop_words\n",
    "\n",
    "df['review'] = remove_stop_words(df['review'])\n",
    "print(df['review'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    mr costner dragged movie far longer necessary ...\n",
      "1    example majority action film generic boring th...\n",
      "2    first hate moronic rapper couldnt act gun pres...\n",
      "3    even beatles could write song everyone liked a...\n",
      "4    brass picture movie fitting word really somewh...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# normalize words by grouping different forms of the same word into one, eg: car, cars, car's, cars' -> car. The below uses lemmatization (other option is stemming)\n",
    "\n",
    "def get_lemmatized_text(corpus):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [' '.join([lemmatizer.lemmatize(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "df['review'] = get_lemmatized_text(df['review'])\n",
    "print(df['review'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0.86572 for method #1\n"
     ]
    }
   ],
   "source": [
    "# Train model method #1 (simplest)\n",
    "# First try one hot encoding where each review is turned into a matrix of 0's and 1's, with each 0 or 1 representing whether a certain word is present in the review. Every unique word across all reviews will have an index somewhere in the matrix.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# shuffle\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# create train and test datasets\n",
    "df_train = df[df['type'] == 'train']\n",
    "df_test = df[df['type'] == 'test']\n",
    "\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(df_train['review'])\n",
    "X_train = cv.transform(df_train['review'])\n",
    "X_test = cv.transform(df_test['review'])\n",
    "\n",
    "target_train = df_train['label']\n",
    "target_test = df_test['label']\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, target_train)\n",
    "\n",
    "print(\"Accuracy of %s for method #1\" % accuracy_score(target_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on method #1 (plain logistic regression) for C=0.01: 0.87468\n",
      "Accuracy on method #1 (plain logistic regression) for C=0.05: 0.8774\n",
      "Accuracy on method #1 (plain logistic regression) for C=0.25: 0.87308\n",
      "Accuracy on method #1 (plain logistic regression) for C=0.5: 0.87008\n",
      "Accuracy on method #1 (plain logistic regression) for C=1: 0.86572\n"
     ]
    }
   ],
   "source": [
    "# Can also try logistic regression with different values of c\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    model = LogisticRegression(C=c)\n",
    "    model.fit(X_train, target_train)\n",
    "    print (\"Accuracy on method #1 (plain logistic regression) for C=%s: %s\" % (c, accuracy_score(target_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on method #2 (logistic regression with ngrams) for C=0.01: 0.8806\n",
      "Accuracy on method #2 (logistic regression with ngrams) for C=0.05: 0.88652\n",
      "Accuracy on method #2 (logistic regression with ngrams) for C=0.25: 0.8872\n",
      "Accuracy on method #2 (logistic regression with ngrams) for C=0.5: 0.88768\n",
      "Accuracy on method #2 (logistic regression with ngrams) for C=1: 0.88728\n"
     ]
    }
   ],
   "source": [
    "# Train model method #2 - use ngrams to consider more than one word at once \n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
    "ngram_vectorizer.fit(df_train['review'])\n",
    "X_train = ngram_vectorizer.transform(df_train['review'])\n",
    "X_test = ngram_vectorizer.transform(df_test['review'])\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "    model = LogisticRegression(C=c)\n",
    "    model.fit(X_train, target_train)\n",
    "    print (\"Accuracy on method #2 (logistic regression with ngrams) for C=%s: %s\" % (c, accuracy_score(target_test, model.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on method #3 (random forest): 0.838\n"
     ]
    }
   ],
   "source": [
    "# Train model method #3 - random forest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = 6000) \n",
    "train_data_features = vectorizer.fit_transform(df_train['review'])\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data_features, df_train['label'], test_size=0.2, random_state=0)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "forest = forest.fit(x_train, y_train)\n",
    "\n",
    "result = forest.predict(x_test)\n",
    "print('Accuracy on method #3 (random forest): %s' % (accuracy_score(y_test, result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/3\n",
      "20000/20000 [==============================] - 92s 5ms/step - loss: 0.4350 - acc: 0.8132 - val_loss: 0.2890 - val_acc: 0.8776\n",
      "Epoch 2/3\n",
      "20000/20000 [==============================] - 92s 5ms/step - loss: 0.2340 - acc: 0.9107 - val_loss: 0.2841 - val_acc: 0.8814\n",
      "Epoch 3/3\n",
      "20000/20000 [==============================] - 89s 4ms/step - loss: 0.1724 - acc: 0.9390 - val_loss: 0.3175 - val_acc: 0.8716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19120a36668>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model with method #4\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Convolution1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "max_features = 6000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(df_train['review'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(df_train['review'])\n",
    "\n",
    "maxlen = 130\n",
    "\n",
    "X_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "\n",
    "y_train = df_train['label']\n",
    "y_train = y_train.replace('neg', 0)\n",
    "y_train = y_train.replace('pos', 1)\n",
    "\n",
    "embed_size = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_size))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 3 # validation loss increases (starts to overfit) \n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85816\n",
      "F1-score: 0.8525816911948116\n"
     ]
    }
   ],
   "source": [
    "# Predict with method #4\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(df_test['review'])\n",
    "\n",
    "X_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "\n",
    "y_test = df_test['label']\n",
    "y_test = y_test.replace('neg', 0)\n",
    "y_test = y_test.replace('pos', 1)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "y_pred = (prediction > 0.5)\n",
    "\n",
    "print(\"Accuracy: %s\" % accuracy_score(y_test, y_pred))\n",
    "print('F1-score: {0}'.format(f1_score(y_pred, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
